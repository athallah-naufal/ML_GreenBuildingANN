{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-27T10:17:08.896477Z",
     "start_time": "2024-10-27T10:17:08.892031Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs('Model', exist_ok=True)\n",
    "os.makedirs('Excel', exist_ok=True)\n",
    "os.makedirs('Gambar', exist_ok=True)\n",
    "os.makedirs('Gambar/Heatmap', exist_ok=True)\n",
    "os.makedirs('Gambar/Best Worst', exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9c5b6f1700b5371"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T10:17:10.625756Z",
     "start_time": "2024-10-27T10:17:10.596159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load Datasets\n",
    "test_indices = np.load('Array/test_indices.npy')\n",
    "train_indices = np.load('Array/train_indices.npy')\n",
    "\n",
    "# Load the data\n",
    "data_x = np.load('input_x.npy')\n",
    "data_y = np.load('input_y.npy')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train_true = data_x[train_indices]\n",
    "y_train_true = data_y[train_indices]\n",
    "x_test_true = data_x[test_indices]\n",
    "y_test_true = data_y[test_indices]\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Convert data to tensor if needed and move to the correct device\n",
    "Tensor_X = torch.tensor(x_test_true, dtype=torch.float32).to(device)\n",
    "\n",
    "# Define your model architecture\n",
    "class ANNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim, dropout_rate=0.3):\n",
    "        super(ANNModel, self).__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, h_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))  # Dropout to prevent overfitting\n",
    "            prev_dim = h_dim\n",
    "        layers.append(nn.Linear(prev_dim, output_dim))  # Output layer (no activation for regression)\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Load the best hyperparameters\n",
    "best_hyperparameters = torch.load('Model/Best_Hyperparameters.pth')\n",
    "\n",
    "# Extract each parameter\n",
    "best_hidden_layers = best_hyperparameters['hidden_layers']\n",
    "best_hidden_units = [best_hyperparameters[f'n_units_l{i}'] for i in range(best_hidden_layers)]\n",
    "best_dropout_rate = best_hyperparameters['dropout_rate']\n",
    "best_lr = best_hyperparameters['lr']\n",
    "best_optimizer_name = best_hyperparameters['optimizer']\n",
    "\n",
    "# Re-initialize the model with the loaded best hyperparameters\n",
    "model = ANNModel(\n",
    "    input_dim=8,\n",
    "    hidden_dims=best_hidden_units,\n",
    "    output_dim=462,\n",
    "    dropout_rate=best_dropout_rate\n",
    ").to(device)  # Ensure 'device' is defined (e.g., device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "# Set up the optimizer using the loaded hyperparameter\n",
    "best_optimizer = getattr(optim, best_optimizer_name)(model.parameters(), lr=best_lr)\n",
    "\n",
    "# Define the loss criterion\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Load the best model weights\n",
    "model.load_state_dict(torch.load('Model/ANN_Model.pt'))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Predict with the model\n",
    "with torch.no_grad():  # No gradients needed for inference\n",
    "    predictions = model(Tensor_X)\n",
    "\n",
    "# Convert predictions to a numpy array or DataFrame as needed\n",
    "y_pred = predictions.cpu().numpy()\n",
    "\n",
    "# Create Pytorch Datasets\n",
    "\n",
    "Tensor_X = torch.tensor(x_test_true, dtype=torch.float32)\n",
    "Tensor_X.to(device)"
   ],
   "id": "ac42849d648e92bc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Athal\\AppData\\Local\\Temp\\ipykernel_30424\\3300693080.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_hyperparameters = torch.load('Model/Best_Hyperparameters.pth')\n",
      "C:\\Users\\Athal\\AppData\\Local\\Temp\\ipykernel_30424\\3300693080.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('Model/ANN_Model.pt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.3333, 0.7785, 0.0469, 0.0769, 0.4218, 1.0000],\n",
       "        [0.0000, 0.0000, 0.3333, 0.3627, 0.3750, 0.2115, 0.2007, 0.8000],\n",
       "        [0.0000, 0.0000, 0.3333, 0.3671, 0.7344, 0.1538, 0.3946, 0.3667],\n",
       "        [0.0000, 0.0000, 0.3333, 0.2726, 0.0000, 0.0385, 0.6803, 0.9333],\n",
       "        [0.0000, 0.0000, 0.6667, 0.2189, 0.7344, 1.0000, 0.9796, 0.0000],\n",
       "        [0.0000, 0.0000, 0.6667, 0.2726, 0.0000, 0.0385, 0.6803, 0.9333],\n",
       "        [0.0000, 0.0000, 0.6667, 0.2233, 0.2188, 0.1731, 0.7415, 0.6667],\n",
       "        [0.0000, 0.0000, 1.0000, 1.0000, 0.7500, 0.0577, 0.3605, 0.3000],\n",
       "        [0.0000, 0.0000, 1.0000, 0.4171, 1.0000, 0.9038, 0.0000, 0.2000],\n",
       "        [0.0000, 0.0000, 1.0000, 0.5820, 0.6094, 0.7115, 1.0000, 0.1333],\n",
       "        [0.0000, 0.0000, 1.0000, 0.3671, 0.7344, 0.1538, 0.3946, 0.3667],\n",
       "        [0.0000, 1.0000, 0.0000, 1.0000, 0.7500, 0.0577, 0.3605, 0.3000],\n",
       "        [0.0000, 1.0000, 0.0000, 0.2189, 0.7344, 1.0000, 0.9796, 0.0000],\n",
       "        [0.0000, 1.0000, 0.3333, 0.4171, 1.0000, 0.9038, 0.0000, 0.2000],\n",
       "        [0.0000, 1.0000, 0.3333, 0.6467, 0.1094, 0.7692, 0.0510, 0.5000],\n",
       "        [0.0000, 1.0000, 0.3333, 0.2189, 0.7344, 1.0000, 0.9796, 0.0000],\n",
       "        [0.0000, 1.0000, 0.3333, 0.3627, 0.3750, 0.2115, 0.2007, 0.8000],\n",
       "        [0.0000, 1.0000, 1.0000, 0.6467, 0.1094, 0.7692, 0.0510, 0.5000],\n",
       "        [0.0000, 1.0000, 1.0000, 0.3627, 0.3750, 0.2115, 0.2007, 0.8000],\n",
       "        [0.0000, 1.0000, 1.0000, 0.3671, 0.7344, 0.1538, 0.3946, 0.3667],\n",
       "        [0.0000, 1.0000, 1.0000, 0.2233, 0.2188, 0.1731, 0.7415, 0.6667],\n",
       "        [1.0000, 0.0000, 0.0000, 0.6467, 0.1094, 0.7692, 0.0510, 0.5000],\n",
       "        [1.0000, 0.0000, 0.0000, 0.3671, 0.7344, 0.1538, 0.3946, 0.3667],\n",
       "        [1.0000, 0.0000, 0.0000, 0.2726, 0.0000, 0.0385, 0.6803, 0.9333],\n",
       "        [1.0000, 0.0000, 0.3333, 0.2233, 0.2188, 0.1731, 0.7415, 0.6667],\n",
       "        [1.0000, 0.0000, 0.6667, 0.6467, 0.1094, 0.7692, 0.0510, 0.5000],\n",
       "        [1.0000, 0.0000, 0.6667, 0.2189, 0.7344, 1.0000, 0.9796, 0.0000],\n",
       "        [1.0000, 0.0000, 1.0000, 0.3671, 0.7344, 0.1538, 0.3946, 0.3667],\n",
       "        [1.0000, 0.0000, 1.0000, 0.2726, 0.0000, 0.0385, 0.6803, 0.9333],\n",
       "        [1.0000, 1.0000, 0.0000, 0.5820, 0.6094, 0.7115, 1.0000, 0.1333],\n",
       "        [1.0000, 1.0000, 0.0000, 0.3627, 0.3750, 0.2115, 0.2007, 0.8000],\n",
       "        [1.0000, 1.0000, 0.0000, 0.2233, 0.2188, 0.1731, 0.7415, 0.6667],\n",
       "        [1.0000, 1.0000, 0.3333, 0.2189, 0.7344, 1.0000, 0.9796, 0.0000],\n",
       "        [1.0000, 1.0000, 0.6667, 0.7785, 0.0469, 0.0769, 0.4218, 1.0000],\n",
       "        [1.0000, 1.0000, 0.6667, 0.6467, 0.1094, 0.7692, 0.0510, 0.5000],\n",
       "        [1.0000, 1.0000, 0.6667, 0.2189, 0.7344, 1.0000, 0.9796, 0.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 0.4171, 1.0000, 0.9038, 0.0000, 0.2000],\n",
       "        [1.0000, 1.0000, 1.0000, 0.3671, 0.7344, 0.1538, 0.3946, 0.3667],\n",
       "        [1.0000, 1.0000, 1.0000, 0.2233, 0.2188, 0.1731, 0.7415, 0.6667]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T10:17:15.228790Z",
     "start_time": "2024-10-27T10:17:15.221665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Calculate metrics definition\n",
    "def calculate_metrics(true, pred):\n",
    "    r2 = r2_score(true, pred, multioutput='uniform_average')\n",
    "    mse = mean_squared_error(true, pred)\n",
    "    mae = mean_absolute_error(true, pred)\n",
    "    return r2, mse, mae\n",
    "\n",
    "# Calculate score\n",
    "r2_train, mse_train, mae_train = calculate_metrics(y_test_true, y_pred)\n",
    "\n",
    "\n",
    "# Output the results\n",
    "print(\"\\n===== Model Performance =====\")\n",
    "print(f\"  R2 Score: {r2_train:.4f}\")\n",
    "print(f\"  MSE: {mse_train:.4f}\")\n",
    "print(f\"  MAE: {mae_train:.4f}\")\n"
   ],
   "id": "f692719b8e86208b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Model Performance =====\n",
      "  R2 Score: 0.8623\n",
      "  MSE: 0.0056\n",
      "  MAE: 0.0415\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f6fe170f31e9a0cd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
